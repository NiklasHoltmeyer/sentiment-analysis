{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepSentiment.Preprocessing.CleanText import CleanText\n",
    "from DeepSentiment.Dataset import Sentiment140\n",
    "from DeepSentiment.Consts import (\n",
    "    Global as Global, \n",
    "    Glove as Glove, \n",
    "    Paths as Paths, \n",
    "    Preprocessing as Preprocessing, \n",
    "    Training as Training \n",
    ")\n",
    "from DeepSentiment.Networks.Tensorflow.Model import Model as TFModel\n",
    "from DeepSentiment.Networks.Transformer.Model import Model as STModel\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepSentiment.Preprocessing.CleanText import CleanText\n",
    "from DeepSentiment.Dataset import Sentiment140\n",
    "from DeepSentiment.Preprocessing.CleanText import CleanText\n",
    "from DeepSentiment.Consts import (\n",
    "    Global as Global, \n",
    "    Glove as Glove, \n",
    "    Paths as Paths, \n",
    "    Preprocessing as Preprocessing, \n",
    "    Training as Training \n",
    ")\n",
    "\n",
    "trainArgs = Training.trainArgs\n",
    "trainRatio = trainArgs[\"train_size_ratio\"]\n",
    "\n",
    "s140_W2V, s140_GloVe = Sentiment140.Dataset(path=Paths.SENTIMENT140_DATASET, \n",
    "                                parsedPath=Paths.SENTIMENT140_DATASET_PARSED,\n",
    "                                embeddingDim=Glove.GLOVE_DIM, \n",
    "                                MAX_SEQUENCE_LENGTH=Preprocessing.MAX_SEQUENCE_LENGTH,\n",
    "                                args=trainArgs), \\\n",
    "                        Sentiment140.Dataset(path=Paths.SENTIMENT140_DATASET, \n",
    "                                parsedPath=Paths.SENTIMENT140_DATASET_PARSED,\n",
    "                                embeddingDim=Glove.GLOVE_DIM, \n",
    "                                MAX_SEQUENCE_LENGTH=Preprocessing.MAX_SEQUENCE_LENGTH,\n",
    "                                args=trainArgs)\n",
    "\n",
    "train_data_W2V, test_data_W2V, labelDecoder_W2V = s140_W2V.load(padInput=False, \n",
    "                                                        DEBUG=True, \n",
    "                                                        cleanFN = CleanText().cleanText,\n",
    "                                                        BERT = False) #Bert = False = TransformLabels!\n",
    "\n",
    "\n",
    "train_data_GloVe, test_data_GloVe, labelDecoder_GloVe = s140_GloVe.load(padInput=True, \n",
    "                                                        DEBUG=True, \n",
    "                                                        cleanFN = CleanText().cleanText,\n",
    "                                                        BERT = False) #Bert = False = TransformLabels!\n",
    "\n",
    "test_data_GloVe_fixed = test_data_GloVe[0], [x[0] for x in test_data_GloVe[1]]   #[1] -> 1\n",
    "train_data_GloVe_fixed = train_data_GloVe[0], [x[0] for x in train_data_GloVe[1]]\n",
    "\n",
    "test_data_W2V_fixed = test_data_W2V[0], [x[0] for x in test_data_W2V[1]]   #[1] -> 1\n",
    "train_data_W2V_fixed = train_data_W2V[0], [x[0] for x in train_data_W2V[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ImdbSentimentDataset import ImdbSentimentDataset\n",
    "#from clean_text import CleanText\n",
    "#imdbDS = ImdbSentimentDataset(Paths.IMDB_DATASET, Paths.IMDB_DATASET_Parsed)\n",
    "\n",
    "#imdbDF, imdbGloVeDF = imdbDS.load(CleanText().cleanText), imdbDS.load(CleanText().cleanText)\n",
    "#imdbDS.removeCache()\n",
    "\n",
    "#imdbGloVeDF['text'] = imdbGloVeDF['text'].apply(s140_GloVe.padInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd \n",
    "\n",
    "def encodeLabel(y, threshhold=0.4):\n",
    "    if y < threshhold:\n",
    "        return 0 #negative\n",
    "    if y > threshhold:\n",
    "        return 1 #positive\n",
    "    return 0.5 #neutral\n",
    "\n",
    "def getMetrics(df):\n",
    "    ''' binary label, df columns y, predictions '''\n",
    "    confusionMatrix = confusion_matrix(df['y'], df['predictions'])\n",
    "    tn, fp, fn, tp = confusionMatrix.ravel()\n",
    "    total = tn + fp + fn + tp\n",
    "\n",
    "    Accuracy = (tp+tn) /total\n",
    "    Precision = tp/(tp+fp)\n",
    "    Recall = tp/(tp+fn)\n",
    "    F1 = 2*Recall*Precision/(Recall+Precision)\n",
    "    \n",
    "    return {        \n",
    "        \"Accuracy\" : Accuracy,\n",
    "        \"Precision\" : Precision,\n",
    "        \"Recall\" : Recall,\n",
    "        \"F1\" : F1,\n",
    "        \"tn\" : tn, \n",
    "        \"fp\" : fp, \n",
    "        \"fn\" : fn, \n",
    "        \"tp\" : tp\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluateModel(model, data, verbose=2, use_multiprocessing=True):\n",
    "    \"\"\" TF-Model \"\"\"\n",
    "    dataX, dataY = data\n",
    "    \n",
    "    predictions = model.predict(\n",
    "        dataX, \n",
    "        batch_size=trainArgs['train_batch_size'],\n",
    "        verbose=verbose,\n",
    "        use_multiprocessing=use_multiprocessing)        \n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    #df['x'] = dataX\n",
    "    df['y'] = dataY\n",
    "    df['predictions'] = [encodeLabel(prediction) for prediction in predictions]  \n",
    "    \n",
    "    return getMetrics(df)\n",
    "\n",
    "def metricCSVRow(metric):\n",
    "    return \";\".join([str(v) for v in metric.values()])\n",
    "\n",
    "def metricHeaderRow(metric):\n",
    "    return \";\".join([k for k in metricDict.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "modelNames = os.listdir(Paths.MODEL)  \n",
    "modelNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paths.MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TF-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for modelName in modelNames:\n",
    "    splittedName = modelName.split(\"_\")\n",
    "    GLOVE = \"GLOVE\" in modelName\n",
    "    train_data, test_data = (train_data_GloVe_fixed, test_data_GloVe_fixed) if GLOVE else (train_data_W2V_fixed, test_data_W2V_fixed) \n",
    "    \n",
    "    try:    \n",
    "        model = TFModel().loadModel(GLOVE = \"GLOVE\" in splittedName,\n",
    "            CNN_LAYER = \"CNN\" in splittedName,\n",
    "            POOLING_LAYER = \"POOLING\" in splittedName,\n",
    "            GRU_LAYER = \"GRU\" in splittedName,\n",
    "            BiLSTM_Layer = \"BiLSTM\" in splittedName,\n",
    "            LSTM_Layer = \"LSTM\" in splittedName,\n",
    "            DENSE_LAYER = \"DENSE\" in splittedName)\n",
    "        trainResult = evaluateModel(model, train_data, verbose=1)\n",
    "        testResult = evaluateModel(model, test_data, verbose=1)\n",
    "\n",
    "        results.append([modelName, trainResult, testResult])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Modelname: {modelName}, EXCEPTION: \")\n",
    "        print(e)\n",
    "        print(f\"---------{modelName}---------\")\n",
    "        print(f\"---------{modelName}---------\")\n",
    "        print(f\"---------{modelName}---------\")\n",
    "        results.append([modelName, \"ERROR\", \"ERROR\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorResults = [x for x in results if x[1] == x[2] and x[1] in 'ERROR']\n",
    "validResults = [x for x in results if not (x[1] == x[2] and x[1] in 'ERROR')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x[0] for x in validResults]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io  \n",
    "from datetime import datetime\n",
    "\n",
    "metricResult = lambda validResult : \";\".join([str(v) for (k, v) in validResult.items()])\n",
    "metricResultHeader = lambda x, pre: \";\".join([(pre + str(k)) for k in x.keys()])\n",
    "\n",
    "#csvResults = [\";\".join([validResult[0],validResult[1],\";\".join([])]) for validResult in validResults]\n",
    "header = \";\".join([\"modelName\", metricResultHeader(validResults[0][1], \"train\"), metricResultHeader(validResults[0][2], \"test\")])\n",
    "_validResults = [(validResult[0], metricResult(validResult[1]), metricResult(validResult[2])) for validResult in validResults]\n",
    "\n",
    "combined = header + '\\n' + '\\n'+ '\\n' + \"\\n\".join([\";\".join(validResult) for validResult in _validResults])\n",
    "resultDF = pd.read_csv(  io.StringIO(combined)  , sep=\";\")\n",
    "\n",
    "resultPath = Paths.RESULTS_BASE + \"//result_\" + datetime.now().strftime('%Y-%m-%d_%H-%M-%S')  + \".csv\"\n",
    "resultDF.to_csv(resultPath,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errorResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x[0] for x in validResults]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
